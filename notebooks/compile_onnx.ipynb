{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
=======
   "execution_count": 2,
>>>>>>> 0717b8ae490ab734737f598b3c6c06b610fdc940
   "id": "592e4408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm\n",
    "from tvm import relay\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tvm.contrib.download import download_testdata\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": 1,
   "id": "e1b76e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote labels.txt with 1000 classes\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import ResNet18_Weights\n",
    "labels = ResNet18_Weights.DEFAULT.meta[\"categories\"]  # 1000 labels\n",
    "with open(\"labels.txt\",\"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(labels))\n",
    "print(\"Wrote labels.txt with\", len(labels), \"classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
>>>>>>> 0717b8ae490ab734737f598b3c6c06b610fdc940
   "id": "1c622904",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model_name = \"resnet18\"\n",
    "model = getattr(torchvision.models, model_name)(pretrained=True)\n",
    "model = model.eval()\n",
    "\n",
    "# We grab the TorchScripted model via tracing\n",
    "input_shape = [1, 3, 224, 224]\n",
    "input_data = torch.randn(input_shape)\n",
    "scripted_model = torch.jit.trace(model, input_data).eval()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": 4,
>>>>>>> 0717b8ae490ab734737f598b3c6c06b610fdc940
   "id": "3f289b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img_url = \"https://github.com/dmlc/mxnet.js/blob/main/data/cat.png?raw=true\"\n",
    "img_path = download_testdata(img_url, \"cat.png\", module=\"data\")\n",
    "img = Image.open(img_path).resize((224, 224))\n",
    "\n",
    "# Preprocess the image and convert to tensor\n",
    "from torchvision import transforms\n",
    "\n",
    "my_preprocess = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "img = my_preprocess(img)\n",
    "img = np.expand_dims(img, 0)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 5,
>>>>>>> 0717b8ae490ab734737f598b3c6c06b610fdc940
   "id": "fd3aafda",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_name = \"input0\"\n",
    "shape_list = [(input_name, img.shape)]\n",
    "mod, params = relay.frontend.from_pytorch(scripted_model, shape_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bb9966",
   "metadata": {},
   "source": [
    "## Choosing the Target Architecture\n",
    "\n",
    "In TVM, a target defines how the model will be compiled for the hardware. You can either use:\n",
    "\n",
    "1. **Target strings**: e.g., `\"llvm -mtriple=aarch64-linux-gnu -mcpu=cortex-a72 -mattr=+neon\"`\n",
    "2. **Helper functions**: e.g., `tvm.target.arm_cpu(model=\"raspi4\")` or `tvm.target.cuda()`\n",
    "\n",
    "| Device | TVM Helper | Example Target String |\n",
    "|--------|------------|---------------------|\n",
    "| Raspberry Pi 4 (64-bit) | `tvm.target.arm_cpu(model=\"raspi4\")` | `llvm -mtriple=aarch64-linux-gnu -mcpu=cortex-a72 -mattr=+neon` |\n",
    "| Raspberry Pi 3 / Zero 2 | `tvm.target.arm_cpu(model=\"raspi3\")` | `llvm -mtriple=aarch64-linux-gnu -mcpu=cortex-a53 -mattr=+neon` |\n",
    "| x86_64 Desktop | `tvm.target.llvm(mcpu=\"native\")` | `llvm -mcpu=native` |\n",
    "| Jetson Xavier NX GPU | `tvm.target.cuda(arch=\"sm_75\")` | `cuda -arch=sm_75` |\n",
    "| STM32 Microcontrollers | `tvm.target.stm32(series=\"stm32H7xx\")` | `c -mcpu=cortex-m7` |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40c94a5",
   "metadata": {},
   "source": [
    "### Cross-Compilation Notes\n",
    "\n",
    "When compiling on a host machine (e.g., x86 laptop) for an embedded target (Raspberry Pi, Jetson), \n",
    "TVM uses cross-compilation. Make sure to:\n",
    "\n",
    "- Specify `mtriple` to match target OS/architecture.\n",
    "- Specify `mcpu` to match the exact CPU core.\n",
    "- Optionally specify `mattr` for hardware features.\n",
    "\n",
    "You can list built-in target tags using:\n",
    "```python\n",
    "tvm.target.list_tags()\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 6,
>>>>>>> 0717b8ae490ab734737f598b3c6c06b610fdc940
   "id": "79ce6683",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One or more operators have not been tuned. Please tune your model for better performance. Use DEBUG logging level to see more details.\n"
     ]
    }
   ],
   "source": [
    "# ==== Pick ONE target string ====\n",
<<<<<<< HEAD
    "# Windows x64 (MinGW)\n",
    "# target_str = \"llvm -mtriple=x86_64-w64-windows-gnu -mcpu=haswell\"\n",
    "\n",
    "# Windows x86 (MinGW)\n",
    "# target_str = \"llvm -mtriple=i686-w64-windows-gnu -mcpu=core2\"\n",
    "\n",
    "# Windows ARM64 (MinGW)\n",
    "# target_str = \"llvm -mtriple=aarch64-w64-windows-gnu -mcpu=neoverse-n1\"\n",
    "\n",
    "# Raspberry Pi 4 (64-bit OS, Cortex-A72)\n",
    "# target_str = \"llvm -mtriple=aarch64-linux-gnu -mcpu=cortex-a72 -mattr=+neon\"\n",
    "\n",
    "# Raspberry Pi 3 / Zero 2 (64-bit OS, Cortex-A53)\n",
    "# target_str = \"llvm -mtriple=aarch64-linux-gnu -mcpu=cortex-a53 -mattr=+neon\"\n",
    "\n",
    "# Raspberry Pi (32-bit userspace, hard-float)\n",
    "# target_str = \"llvm -mtriple=armv7-linux-gnueabihf -mcpu=cortex-a72 -mattr=+neon,+vfp3\"\n",
    "\n",
    "target_host = \"llvm\" # host\n",
    "# Raspberry Pi 4 is typically aarch64, but if running 32-bit OS:\n",
    "target_rpi = \"llvm -keys=cpu -mcpu=cortex-a72 -model=raspi4 -mtriple=armv7l-linux-gnueabihf\"\n",
    "\n",
    "target = tvm.target.Target(target_rpi, host=\"llvm\")\n",
=======
    "\n",
    "# https://tvm.apache.org/docs/reference/api/python/target.html\n",
    "\n",
    "target_host = \"llvm\" # host\n",
    "\n",
    "target = tvm.target.Target(\"llvm\", host=\"llvm\")\n",
    "# target = tvm.target.arm_cpu()\n",
    "\n",
    "# target = tvm.target.rasp()\n",
    "\n",
    "# Pi 4 64-bit OS\n",
    "# target = tvm.target.Target(\"llvm -mtriple=aarch64-linux-gnu -mcpu=cortex-a72 -mattr=+neon -keys=cpu -model=raspi4\", host=target_host)\n",
    "\n",
    "# Pi 4 (A72, 64-bit OS)\n",
    "# target = tvm.target.Target(\"llvm -mtriple=aarch64-linux-gnu -mcpu=cortex-a72 -mattr=+neon\", host=target_host)\n",
    "\n",
    "# Pi 3 / Zero 2 (A53, 64-bit OS)\n",
    "# target = tvm.target.Target(\"llvm -mtriple=aarch64-linux-gnu -mcpu=cortex-a53 -mattr=+neon\", host=target_host)\n",
    "\n",
    "# Pi (32-bit userspace, ARMv7 hard-float)\n",
    "# target = tvm.target.Target(\"llvm -mtriple=armv7-linux-gnueabihf -mcpu=cortex-a72 -mattr=+neon,+vfp3\", host=target_host)\n",
    "\n",
>>>>>>> 0717b8ae490ab734737f598b3c6c06b610fdc940
    "dev = tvm.cpu(0)\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    lib = relay.build(mod, target=target, params=params)\n",
    "\n",
<<<<<<< HEAD
    "lib.export_library(\"resnet18_tvm.so\")"
=======
    "# Save graph JSON\n",
    "with open(\"resnet18_tvm.json\", \"w\") as f_json:\n",
    "    f_json.write(lib.get_graph_json())\n",
    "\n",
    "# Save parameters\n",
    "with open(\"resnet18_tvm.params\", \"wb\") as f_params:\n",
    "    f_params.write(tvm.runtime.save_param_dict(lib.params))\n",
    "\n",
    "from tvm.contrib import cc\n",
    "lib.export_library(\"resnet18_tvm.so\", fcompile=cc.create_shared)"
>>>>>>> 0717b8ae490ab734737f598b3c6c06b610fdc940
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": null,
>>>>>>> 0717b8ae490ab734737f598b3c6c06b610fdc940
   "id": "5027bb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvm.contrib import graph_executor\n",
    "\n",
    "dtype = \"float32\"\n",
    "m = graph_executor.GraphModule(lib[\"default\"](dev))\n",
    "# Set inputs\n",
    "m.set_input(input_name, tvm.nd.array(img.astype(dtype)))\n",
    "# Execute\n",
    "m.run()\n",
    "# Get outputs\n",
    "tvm_output = m.get_output(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4fc3452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relay top-1 id: 281, class name: tabby, tabby cat\n",
      "Torch top-1 id: 281, class name: tabby, tabby cat\n"
     ]
    }
   ],
   "source": [
    "synset_url = \"\".join(\n",
    "    [\n",
    "        \"https://raw.githubusercontent.com/Cadene/\",\n",
    "        \"pretrained-models.pytorch/master/data/\",\n",
    "        \"imagenet_synsets.txt\",\n",
    "    ]\n",
    ")\n",
    "synset_name = \"imagenet_synsets.txt\"\n",
    "synset_path = download_testdata(synset_url, synset_name, module=\"data\")\n",
    "with open(synset_path) as f:\n",
    "    synsets = f.readlines()\n",
    "\n",
    "synsets = [x.strip() for x in synsets]\n",
    "splits = [line.split(\" \") for line in synsets]\n",
    "key_to_classname = {spl[0]: \" \".join(spl[1:]) for spl in splits}\n",
    "\n",
    "class_url = \"\".join(\n",
    "    [\n",
    "        \"https://raw.githubusercontent.com/Cadene/\",\n",
    "        \"pretrained-models.pytorch/master/data/\",\n",
    "        \"imagenet_classes.txt\",\n",
    "    ]\n",
    ")\n",
    "class_name = \"imagenet_classes.txt\"\n",
    "class_path = download_testdata(class_url, class_name, module=\"data\")\n",
    "with open(class_path) as f:\n",
    "    class_id_to_key = f.readlines()\n",
    "\n",
    "class_id_to_key = [x.strip() for x in class_id_to_key]\n",
    "\n",
    "# Get top-1 result for TVM\n",
    "top1_tvm = np.argmax(tvm_output.numpy()[0])\n",
    "tvm_class_key = class_id_to_key[top1_tvm]\n",
    "\n",
    "# Convert input to PyTorch variable and get PyTorch result for comparison\n",
    "with torch.no_grad():\n",
    "    torch_img = torch.from_numpy(img)\n",
    "    output = model(torch_img)\n",
    "\n",
    "    # Get top-1 result for PyTorch\n",
    "    top1_torch = np.argmax(output.numpy())\n",
    "    torch_class_key = class_id_to_key[top1_torch]\n",
    "\n",
    "print(\"Relay top-1 id: {}, class name: {}\".format(top1_tvm, key_to_classname[tvm_class_key]))\n",
    "print(\"Torch top-1 id: {}, class name: {}\".format(top1_torch, key_to_classname[torch_class_key]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
