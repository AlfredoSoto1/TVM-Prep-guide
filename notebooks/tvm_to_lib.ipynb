{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4ffca63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Obtain model graph for `ResNet([...]` with `torch.export.export(..., strict=False)`...\n",
      "[torch.onnx] Obtain model graph for `ResNet([...]` with `torch.export.export(..., strict=False)`... ✅\n",
      "[torch.onnx] Run decomposition...\n",
      "[torch.onnx] Run decomposition... ✅\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... ✅\n",
      "Wrote resnet18.onnx\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models import ResNet18_Weights\n",
    "\n",
    "import onnx\n",
    "from onnxsim import simplify\n",
    "\n",
    "# 1) Load a pretrained model (already trained; we're not training here)\n",
    "model = torchvision.models.resnet18(weights=ResNet18_Weights.DEFAULT).eval()\n",
    "\n",
    "# 2) Dummy input shape must match the model's expectation\n",
    "dummy_input = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "# 3) Export to ONNX: this freezes the graph + weights into a portable file\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    \"resnet18.onnx\",\n",
    "    input_names=[\"input\"],       # name used later in TVM runtime\n",
    "    output_names=[\"logits\"],\n",
    "    opset_version=18,            # operator set version (compatibility)\n",
    "    do_constant_folding=True,    # fold constants for small optimizations\n",
    "    dynamic_axes=None,\n",
    "    training=torch.onnx.TrainingMode.EVAL,\n",
    ")\n",
    "\n",
    "print(\"Wrote resnet18.onnx\")\n",
    "\n",
    "# # Simplify (folds shapes, resolves GlobalAveragePool/Flatten patterns)\n",
    "# model_onnx = onnx.load(\"resnet18.onnx\")\n",
    "# model_simplified, check = simplify(model_onnx)\n",
    "# assert check, \"ONNX simplification failed\"\n",
    "# onnx.save(model_simplified, \"resnet18_simplified.onnx\")\n",
    "# print(\"Wrote resnet18_simplified.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9d998612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "from onnx import helper, numpy_helper\n",
    "\n",
    "model = onnx.load(\"resnet18.onnx\")\n",
    "init_map = {init.name: init for init in model.graph.initializer}\n",
    "touched = False\n",
    "\n",
    "for node in model.graph.node:\n",
    "    if node.op_type == \"ReduceMean\" and len(node.input) == 2:\n",
    "        axes_name = node.input[1]\n",
    "        axes_init = init_map.get(axes_name)\n",
    "        if axes_init is None:\n",
    "            continue\n",
    "        axes = numpy_helper.to_array(axes_init).tolist()\n",
    "        if not isinstance(axes, list):\n",
    "            axes = [int(axes)]\n",
    "        axes = [int(a) for a in axes]\n",
    "        axes = sorted({a if a >= 0 else a + 4 for a in axes})  # convert negatives, keep order\n",
    "\n",
    "        # keep the existing attrs (keepdims / noop_with_empty_axes), add axes attribute\n",
    "        kept_attrs = [attr for attr in node.attribute if attr.name != \"axes\"]\n",
    "        node.ClearField(\"attribute\")\n",
    "        for attr in kept_attrs:\n",
    "            node.attribute.add().CopyFrom(attr)\n",
    "        node.attribute.add().CopyFrom(helper.make_attribute(\"axes\", axes))\n",
    "\n",
    "        # drop the axes tensor input and corresponding initializer/value_info\n",
    "        node.input.pop()\n",
    "        model.graph.initializer.remove(axes_init)\n",
    "        for i in range(len(model.graph.value_info) - 1, -1, -1):\n",
    "            if model.graph.value_info[i].name == axes_name:\n",
    "                del model.graph.value_info[i]\n",
    "        touched = True\n",
    "\n",
    "if not touched:\n",
    "    raise RuntimeError(\"No ReduceMean nodes needed fixing\")\n",
    "onnx.save(model, \"resnet18_fixed.onnx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b32e5076",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One or more operators have not been tuned. Please tune your model for better performance. Use DEBUG logging level to see more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote resnet18_tvm.so\n"
     ]
    }
   ],
   "source": [
    "import onnx, tvm\n",
    "from tvm import relay\n",
    "from tvm.contrib import cc, ndk  # for (cross) compiling shared libs\n",
    "from tvm.contrib import graph_executor\n",
    "\n",
    "# --- Load your ONNX ---\n",
    "onnx_model = onnx.load(\"resnet18_fixed.onnx\")\n",
    "input_name = onnx_model.graph.input[0].name\n",
    "shape_dict = {input_name: (1, 3, 224, 224)}\n",
    "mod, params = relay.frontend.from_onnx(onnx_model, shape_dict, freeze_params=True)\n",
    "\n",
    "# --- Choose ONE target (examples below) ---\n",
    "# Native x86-64 CPU (auto-detect host CPU):\n",
    "target = tvm.target.Target(\"llvm\")\n",
    "\n",
    "# Faster: specialize to a specific CPU (fill with your host CPU name if you want)\n",
    "# target = tvm.target.Target(\"llvm -mcpu=skylake-avx512\")\n",
    "\n",
    "# NVIDIA GPU:\n",
    "# target = tvm.target.Target(\"cuda\")\n",
    "\n",
    "# Vulkan (desktop/mobile GPUs):\n",
    "# target = tvm.target.Target(\"vulkan\")\n",
    "\n",
    "# AMD GPU (ROCm):\n",
    "# target = tvm.target.Target(\"rocm\")\n",
    "\n",
    "# Cross-compile to AArch64 Linux CPU (e.g., Jetson/Nano in CPU mode or ARM server):\n",
    "# target = tvm.target.Target(\"llvm -mtriple=aarch64-linux-gnu -mattr=+neon\")\n",
    "\n",
    "# Android via NDK (CPU):\n",
    "# target = tvm.target.Target(\"llvm -mtriple=armv7a-linux-android\")\n",
    "\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    lib = relay.build(mod, target=target, params=params)\n",
    "\n",
    "  # Simple: produce a Linux .so next to your script\n",
    "lib.export_library(\"resnet18_tvm.so\")\n",
    "print(\"Wrote resnet18_tvm.so\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1dd149",
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Traceback (most recent call last):\n  8: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::transform::Pass, tvm::IRModule)>::AssignTypedLambda<tvm::transform::{lambda(tvm::transform::Pass, tvm::IRModule)#7}>(tvm::transform::{lambda(tvm::transform::Pass, tvm::IRModule)#7}, std::string)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)\n  7: tvm::transform::Pass::operator()(tvm::IRModule) const\n  6: tvm::transform::Pass::operator()(tvm::IRModule, tvm::transform::PassContext const&) const\n  5: tvm::transform::ModulePassNode::operator()(tvm::IRModule, tvm::transform::PassContext const&) const\n  4: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::IRModule, tvm::transform::PassContext)>::AssignTypedLambda<tvm::relay::transform::InferType()::{lambda(tvm::IRModule, tvm::transform::PassContext const&)#1}>(tvm::relay::transform::InferType()::{lambda(tvm::IRModule, tvm::transform::PassContext const&)#1})::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)\n  3: tvm::relay::TypeInferencer::Infer(tvm::GlobalVar, tvm::relay::Function)\n  2: tvm::relay::TypeSolver::Solve()\n  1: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<bool (tvm::runtime::Array<tvm::Type, void> const&, int, tvm::Attrs const&, tvm::TypeReporter const&)>::AssignTypedLambda<bool (*)(tvm::runtime::Array<tvm::Type, void> const&, int, tvm::Attrs const&, tvm::TypeReporter const&)>(bool (*)(tvm::runtime::Array<tvm::Type, void> const&, int, tvm::Attrs const&, tvm::TypeReporter const&))::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)\n  0: tvm::relay::ReshapeRel(tvm::runtime::Array<tvm::Type, void> const&, int, tvm::Attrs const&, tvm::TypeReporter const&)\n  File \"/workspace/tvm/src/relay/op/tensor/transform.cc\", line 795\nInternalError: Check failed: oshape_sum == data_shape_sum (512 vs. 3584) : Input tensor shape(1,512,7,1) and reshaped shape(1,512) are not compatible!",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInternalError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     21\u001b[39m dtype = \u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# 3. Import the ONNX model to the Relay IR\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# The result is a Relay Module (`mod`) and parameters (`params`)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m mod, params = \u001b[43mrelay\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrontend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_onnx\u001b[49m\u001b[43m(\u001b[49m\u001b[43monnx_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreeze_params\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# 4. Compile the Relay Module\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# opt_level=3 applies aggressive optimizations\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m tvm.transform.PassContext(opt_level=\u001b[32m3\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/tvm/relay/frontend/onnx.py:7220\u001b[39m, in \u001b[36mfrom_onnx\u001b[39m\u001b[34m(model, shape, dtype, opset, freeze_params, convert_config, export_node_renamed_model_path)\u001b[39m\n\u001b[32m   7218\u001b[39m \u001b[38;5;66;03m# Use the graph proto as a scope so that ops can access other nodes if needed.\u001b[39;00m\n\u001b[32m   7219\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m g:\n\u001b[32m-> \u001b[39m\u001b[32m7220\u001b[39m     mod, params = \u001b[43mg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_onnx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   7222\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m export_node_renamed_model_path:\n\u001b[32m   7223\u001b[39m     export_model(export_node_renamed_model_path, graph)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/tvm/relay/frontend/onnx.py:6839\u001b[39m, in \u001b[36mGraphProto.from_onnx\u001b[39m\u001b[34m(self, graph, opset, get_output_expr)\u001b[39m\n\u001b[32m   6837\u001b[39m \u001b[38;5;28mself\u001b[39m._check_user_inputs_in_outermost_graph_scope()\n\u001b[32m   6838\u001b[39m \u001b[38;5;28mself\u001b[39m._check_for_unsupported_ops(graph)\n\u001b[32m-> \u001b[39m\u001b[32m6839\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_construct_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6841\u001b[39m \u001b[38;5;66;03m# now return the outputs\u001b[39;00m\n\u001b[32m   6842\u001b[39m outputs = [\u001b[38;5;28mself\u001b[39m._nodes[\u001b[38;5;28mself\u001b[39m._parse_value_proto(i)] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m graph.output]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/tvm/relay/frontend/onnx.py:6954\u001b[39m, in \u001b[36mGraphProto._construct_nodes\u001b[39m\u001b[34m(self, graph)\u001b[39m\n\u001b[32m   6951\u001b[39m attr[\u001b[33m\"\u001b[39m\u001b[33mtvm_custom\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m] = i_name\n\u001b[32m   6952\u001b[39m attr[\u001b[33m\"\u001b[39m\u001b[33mtvm_custom\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mnum_outputs\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mlen\u001b[39m(node_output)\n\u001b[32m-> \u001b[39m\u001b[32m6954\u001b[39m op = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_operator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mopset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6955\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(op, _expr.TupleWrapper):\n\u001b[32m   6956\u001b[39m     outputs_num = \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/tvm/relay/frontend/onnx.py:7078\u001b[39m, in \u001b[36mGraphProto._convert_operator\u001b[39m\u001b[34m(self, op_name, inputs, attrs, opset)\u001b[39m\n\u001b[32m   7076\u001b[39m     sym = get_relay_op(op_name)(*inputs, **attrs)\n\u001b[32m   7077\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m op_name \u001b[38;5;129;01min\u001b[39;00m convert_map:\n\u001b[32m-> \u001b[39m\u001b[32m7078\u001b[39m     sym = \u001b[43mconvert_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   7079\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   7080\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOperator \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mop_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not implemented.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/tvm/relay/frontend/onnx.py:1840\u001b[39m, in \u001b[36mGemm._impl_v1\u001b[39m\u001b[34m(cls, inputs, attr, params)\u001b[39m\n\u001b[32m   1835\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m   1836\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_impl_v1\u001b[39m(\u001b[38;5;28mcls\u001b[39m, inputs, attr, params):\n\u001b[32m   1837\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[32m   1838\u001b[39m         \u001b[38;5;28mlen\u001b[39m(inputs) == \u001b[32m3\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(inputs) == \u001b[32m2\u001b[39m\n\u001b[32m   1839\u001b[39m     ), \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGemm op take 2 or 3 inputs, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(inputs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m given\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1840\u001b[39m     input0_state = \u001b[43minfer_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1841\u001b[39m     dtype = input0_state.checked_type.dtype\n\u001b[32m   1842\u001b[39m     \u001b[38;5;66;03m# Y = alpha * A * B + beta * C\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/tvm/relay/frontend/common.py:505\u001b[39m, in \u001b[36minfer_type\u001b[39m\u001b[34m(node, mod)\u001b[39m\n\u001b[32m    502\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mod \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    503\u001b[39m     new_mod.update(mod)\n\u001b[32m--> \u001b[39m\u001b[32m505\u001b[39m new_mod = \u001b[43m_transform\u001b[49m\u001b[43m.\u001b[49m\u001b[43mInferType\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_mod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    506\u001b[39m entry = new_mod[\u001b[33m\"\u001b[39m\u001b[33mmain\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    507\u001b[39m ret = entry \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, _function.Function) \u001b[38;5;28;01melse\u001b[39;00m entry.body\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/tvm/ir/transform.py:160\u001b[39m, in \u001b[36mPass.__call__\u001b[39m\u001b[34m(self, mod)\u001b[39m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, mod):\n\u001b[32m    147\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Execute the pass. Note that for sequential pass, the dependency among\u001b[39;00m\n\u001b[32m    148\u001b[39m \u001b[33;03m    different passes will be resolved in the backend.\u001b[39;00m\n\u001b[32m    149\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    158\u001b[39m \u001b[33;03m        The updated module after applying this pass.\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ffi_transform_api\u001b[49m\u001b[43m.\u001b[49m\u001b[43mRunPass\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmod\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/tvm/_ffi/_ctypes/packed_func.py:239\u001b[39m, in \u001b[36mPackedFuncBase.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    227\u001b[39m ret_tcode = ctypes.c_int()\n\u001b[32m    228\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    229\u001b[39m     _LIB.TVMFuncCall(\n\u001b[32m    230\u001b[39m         \u001b[38;5;28mself\u001b[39m.handle,\n\u001b[32m   (...)\u001b[39m\u001b[32m    237\u001b[39m     != \u001b[32m0\u001b[39m\n\u001b[32m    238\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m     \u001b[43mraise_last_ffi_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    240\u001b[39m _ = temp_args\n\u001b[32m    241\u001b[39m _ = args\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/tvm/_ffi/base.py:481\u001b[39m, in \u001b[36mraise_last_ffi_error\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    475\u001b[39m \u001b[38;5;66;03m# The exception PyObject may contain a large amount of state,\u001b[39;00m\n\u001b[32m    476\u001b[39m \u001b[38;5;66;03m# including all stack frames that may be inspected in a later\u001b[39;00m\n\u001b[32m    477\u001b[39m \u001b[38;5;66;03m# PDB post-mortem.  Therefore, we must make sure to remove the\u001b[39;00m\n\u001b[32m    478\u001b[39m \u001b[38;5;66;03m# underlying PyObject* from the C++ side after we retrieve it.\u001b[39;00m\n\u001b[32m    479\u001b[39m _LIB.TVMDropLastPythonError()\n\u001b[32m--> \u001b[39m\u001b[32m481\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m py_err\n",
      "\u001b[31mInternalError\u001b[39m: Traceback (most recent call last):\n  8: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::transform::Pass, tvm::IRModule)>::AssignTypedLambda<tvm::transform::{lambda(tvm::transform::Pass, tvm::IRModule)#7}>(tvm::transform::{lambda(tvm::transform::Pass, tvm::IRModule)#7}, std::string)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)\n  7: tvm::transform::Pass::operator()(tvm::IRModule) const\n  6: tvm::transform::Pass::operator()(tvm::IRModule, tvm::transform::PassContext const&) const\n  5: tvm::transform::ModulePassNode::operator()(tvm::IRModule, tvm::transform::PassContext const&) const\n  4: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::IRModule, tvm::transform::PassContext)>::AssignTypedLambda<tvm::relay::transform::InferType()::{lambda(tvm::IRModule, tvm::transform::PassContext const&)#1}>(tvm::relay::transform::InferType()::{lambda(tvm::IRModule, tvm::transform::PassContext const&)#1})::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)\n  3: tvm::relay::TypeInferencer::Infer(tvm::GlobalVar, tvm::relay::Function)\n  2: tvm::relay::TypeSolver::Solve()\n  1: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<bool (tvm::runtime::Array<tvm::Type, void> const&, int, tvm::Attrs const&, tvm::TypeReporter const&)>::AssignTypedLambda<bool (*)(tvm::runtime::Array<tvm::Type, void> const&, int, tvm::Attrs const&, tvm::TypeReporter const&)>(bool (*)(tvm::runtime::Array<tvm::Type, void> const&, int, tvm::Attrs const&, tvm::TypeReporter const&))::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)\n  0: tvm::relay::ReshapeRel(tvm::runtime::Array<tvm::Type, void> const&, int, tvm::Attrs const&, tvm::TypeReporter const&)\n  File \"/workspace/tvm/src/relay/op/tensor/transform.cc\", line 795\nInternalError: Check failed: oshape_sum == data_shape_sum (512 vs. 3584) : Input tensor shape(1,512,7,1) and reshaped shape(1,512) are not compatible!"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import numpy as np\n",
    "import tvm\n",
    "from tvm import relay\n",
    "\n",
    "target = \"llvm\" \n",
    "\n",
    "# 4. Compile the Relay Module\n",
    "# opt_level=3 applies aggressive optimizations\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    lib = relay.build(mod, target=target, params=params)\n",
    "\n",
    "output_path = \"resnet18_tvm.tar\"\n",
    "lib.export_library(output_path)\n",
    "\n",
    "print(f\"Successfully compiled and saved the deployable module to {output_path}\")\n",
    "\n",
    "# To check the contents (on Linux/macOS):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5610cb28",
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Traceback (most recent call last):\n  8: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::transform::Pass, tvm::IRModule)>::AssignTypedLambda<tvm::transform::{lambda(tvm::transform::Pass, tvm::IRModule)#7}>(tvm::transform::{lambda(tvm::transform::Pass, tvm::IRModule)#7}, std::string)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)\n  7: tvm::transform::Pass::operator()(tvm::IRModule) const\n  6: tvm::transform::Pass::operator()(tvm::IRModule, tvm::transform::PassContext const&) const\n  5: tvm::transform::ModulePassNode::operator()(tvm::IRModule, tvm::transform::PassContext const&) const\n  4: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::IRModule, tvm::transform::PassContext)>::AssignTypedLambda<tvm::relay::transform::InferType()::{lambda(tvm::IRModule, tvm::transform::PassContext const&)#1}>(tvm::relay::transform::InferType()::{lambda(tvm::IRModule, tvm::transform::PassContext const&)#1})::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)\n  3: tvm::relay::TypeInferencer::Infer(tvm::GlobalVar, tvm::relay::Function)\n  2: tvm::relay::TypeSolver::Solve()\n  1: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<bool (tvm::runtime::Array<tvm::Type, void> const&, int, tvm::Attrs const&, tvm::TypeReporter const&)>::AssignTypedLambda<bool (*)(tvm::runtime::Array<tvm::Type, void> const&, int, tvm::Attrs const&, tvm::TypeReporter const&)>(bool (*)(tvm::runtime::Array<tvm::Type, void> const&, int, tvm::Attrs const&, tvm::TypeReporter const&))::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)\n  0: tvm::relay::ReshapeRel(tvm::runtime::Array<tvm::Type, void> const&, int, tvm::Attrs const&, tvm::TypeReporter const&)\n  File \"/workspace/tvm/src/relay/op/tensor/transform.cc\", line 795\nInternalError: Check failed: oshape_sum == data_shape_sum (512 vs. 3584) : Input tensor shape(1,512,7,1) and reshaped shape(1,512) are not compatible!",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInternalError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Import the ONNX model to TVM Relay format\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# The error in your traceback (from_onnx(onnx_model, shape_dict)) implies onnx.mapping was called internally.\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Upgrading onnx should fix this if it's a version incompatibility.\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# mod, params = relay.frontend.from_onnx(onnx_model, shape_dict)\u001b[39;00m\n\u001b[32m     20\u001b[39m shape_dict = {input_name: input_shape}\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m mod, params = \u001b[43mrelay\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrontend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_onnx\u001b[49m\u001b[43m(\u001b[49m\u001b[43monnx_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# mod, params = relay.frontend.from_onnx(\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m#     onnx_model,\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m#     shape={input_name: input_shape},\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     29\u001b[39m \n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Set the compilation target. \"llvm\" for CPU, \"cuda\" for NVIDIA GPUs.\u001b[39;00m\n\u001b[32m     31\u001b[39m target = \u001b[33m\"\u001b[39m\u001b[33mllvm\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;66;03m# or \"cuda\" if you have a GPU and CUDA installed\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/tvm/relay/frontend/onnx.py:7220\u001b[39m, in \u001b[36mfrom_onnx\u001b[39m\u001b[34m(model, shape, dtype, opset, freeze_params, convert_config, export_node_renamed_model_path)\u001b[39m\n\u001b[32m   7218\u001b[39m \u001b[38;5;66;03m# Use the graph proto as a scope so that ops can access other nodes if needed.\u001b[39;00m\n\u001b[32m   7219\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m g:\n\u001b[32m-> \u001b[39m\u001b[32m7220\u001b[39m     mod, params = \u001b[43mg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_onnx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   7222\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m export_node_renamed_model_path:\n\u001b[32m   7223\u001b[39m     export_model(export_node_renamed_model_path, graph)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/tvm/relay/frontend/onnx.py:6839\u001b[39m, in \u001b[36mGraphProto.from_onnx\u001b[39m\u001b[34m(self, graph, opset, get_output_expr)\u001b[39m\n\u001b[32m   6837\u001b[39m \u001b[38;5;28mself\u001b[39m._check_user_inputs_in_outermost_graph_scope()\n\u001b[32m   6838\u001b[39m \u001b[38;5;28mself\u001b[39m._check_for_unsupported_ops(graph)\n\u001b[32m-> \u001b[39m\u001b[32m6839\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_construct_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6841\u001b[39m \u001b[38;5;66;03m# now return the outputs\u001b[39;00m\n\u001b[32m   6842\u001b[39m outputs = [\u001b[38;5;28mself\u001b[39m._nodes[\u001b[38;5;28mself\u001b[39m._parse_value_proto(i)] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m graph.output]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/tvm/relay/frontend/onnx.py:6954\u001b[39m, in \u001b[36mGraphProto._construct_nodes\u001b[39m\u001b[34m(self, graph)\u001b[39m\n\u001b[32m   6951\u001b[39m attr[\u001b[33m\"\u001b[39m\u001b[33mtvm_custom\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m] = i_name\n\u001b[32m   6952\u001b[39m attr[\u001b[33m\"\u001b[39m\u001b[33mtvm_custom\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mnum_outputs\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mlen\u001b[39m(node_output)\n\u001b[32m-> \u001b[39m\u001b[32m6954\u001b[39m op = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_operator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mopset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6955\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(op, _expr.TupleWrapper):\n\u001b[32m   6956\u001b[39m     outputs_num = \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/tvm/relay/frontend/onnx.py:7078\u001b[39m, in \u001b[36mGraphProto._convert_operator\u001b[39m\u001b[34m(self, op_name, inputs, attrs, opset)\u001b[39m\n\u001b[32m   7076\u001b[39m     sym = get_relay_op(op_name)(*inputs, **attrs)\n\u001b[32m   7077\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m op_name \u001b[38;5;129;01min\u001b[39;00m convert_map:\n\u001b[32m-> \u001b[39m\u001b[32m7078\u001b[39m     sym = \u001b[43mconvert_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   7079\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   7080\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOperator \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mop_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not implemented.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/tvm/relay/frontend/onnx.py:1840\u001b[39m, in \u001b[36mGemm._impl_v1\u001b[39m\u001b[34m(cls, inputs, attr, params)\u001b[39m\n\u001b[32m   1835\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m   1836\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_impl_v1\u001b[39m(\u001b[38;5;28mcls\u001b[39m, inputs, attr, params):\n\u001b[32m   1837\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[32m   1838\u001b[39m         \u001b[38;5;28mlen\u001b[39m(inputs) == \u001b[32m3\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(inputs) == \u001b[32m2\u001b[39m\n\u001b[32m   1839\u001b[39m     ), \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGemm op take 2 or 3 inputs, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(inputs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m given\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1840\u001b[39m     input0_state = \u001b[43minfer_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1841\u001b[39m     dtype = input0_state.checked_type.dtype\n\u001b[32m   1842\u001b[39m     \u001b[38;5;66;03m# Y = alpha * A * B + beta * C\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/tvm/relay/frontend/common.py:505\u001b[39m, in \u001b[36minfer_type\u001b[39m\u001b[34m(node, mod)\u001b[39m\n\u001b[32m    502\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mod \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    503\u001b[39m     new_mod.update(mod)\n\u001b[32m--> \u001b[39m\u001b[32m505\u001b[39m new_mod = \u001b[43m_transform\u001b[49m\u001b[43m.\u001b[49m\u001b[43mInferType\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_mod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    506\u001b[39m entry = new_mod[\u001b[33m\"\u001b[39m\u001b[33mmain\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    507\u001b[39m ret = entry \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, _function.Function) \u001b[38;5;28;01melse\u001b[39;00m entry.body\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/tvm/ir/transform.py:160\u001b[39m, in \u001b[36mPass.__call__\u001b[39m\u001b[34m(self, mod)\u001b[39m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, mod):\n\u001b[32m    147\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Execute the pass. Note that for sequential pass, the dependency among\u001b[39;00m\n\u001b[32m    148\u001b[39m \u001b[33;03m    different passes will be resolved in the backend.\u001b[39;00m\n\u001b[32m    149\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    158\u001b[39m \u001b[33;03m        The updated module after applying this pass.\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ffi_transform_api\u001b[49m\u001b[43m.\u001b[49m\u001b[43mRunPass\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmod\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/tvm/_ffi/_ctypes/packed_func.py:239\u001b[39m, in \u001b[36mPackedFuncBase.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    227\u001b[39m ret_tcode = ctypes.c_int()\n\u001b[32m    228\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    229\u001b[39m     _LIB.TVMFuncCall(\n\u001b[32m    230\u001b[39m         \u001b[38;5;28mself\u001b[39m.handle,\n\u001b[32m   (...)\u001b[39m\u001b[32m    237\u001b[39m     != \u001b[32m0\u001b[39m\n\u001b[32m    238\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m     \u001b[43mraise_last_ffi_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    240\u001b[39m _ = temp_args\n\u001b[32m    241\u001b[39m _ = args\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/tvm/_ffi/base.py:481\u001b[39m, in \u001b[36mraise_last_ffi_error\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    475\u001b[39m \u001b[38;5;66;03m# The exception PyObject may contain a large amount of state,\u001b[39;00m\n\u001b[32m    476\u001b[39m \u001b[38;5;66;03m# including all stack frames that may be inspected in a later\u001b[39;00m\n\u001b[32m    477\u001b[39m \u001b[38;5;66;03m# PDB post-mortem.  Therefore, we must make sure to remove the\u001b[39;00m\n\u001b[32m    478\u001b[39m \u001b[38;5;66;03m# underlying PyObject* from the C++ side after we retrieve it.\u001b[39;00m\n\u001b[32m    479\u001b[39m _LIB.TVMDropLastPythonError()\n\u001b[32m--> \u001b[39m\u001b[32m481\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m py_err\n",
      "\u001b[31mInternalError\u001b[39m: Traceback (most recent call last):\n  8: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::transform::Pass, tvm::IRModule)>::AssignTypedLambda<tvm::transform::{lambda(tvm::transform::Pass, tvm::IRModule)#7}>(tvm::transform::{lambda(tvm::transform::Pass, tvm::IRModule)#7}, std::string)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)\n  7: tvm::transform::Pass::operator()(tvm::IRModule) const\n  6: tvm::transform::Pass::operator()(tvm::IRModule, tvm::transform::PassContext const&) const\n  5: tvm::transform::ModulePassNode::operator()(tvm::IRModule, tvm::transform::PassContext const&) const\n  4: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::IRModule, tvm::transform::PassContext)>::AssignTypedLambda<tvm::relay::transform::InferType()::{lambda(tvm::IRModule, tvm::transform::PassContext const&)#1}>(tvm::relay::transform::InferType()::{lambda(tvm::IRModule, tvm::transform::PassContext const&)#1})::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)\n  3: tvm::relay::TypeInferencer::Infer(tvm::GlobalVar, tvm::relay::Function)\n  2: tvm::relay::TypeSolver::Solve()\n  1: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<bool (tvm::runtime::Array<tvm::Type, void> const&, int, tvm::Attrs const&, tvm::TypeReporter const&)>::AssignTypedLambda<bool (*)(tvm::runtime::Array<tvm::Type, void> const&, int, tvm::Attrs const&, tvm::TypeReporter const&)>(bool (*)(tvm::runtime::Array<tvm::Type, void> const&, int, tvm::Attrs const&, tvm::TypeReporter const&))::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)\n  0: tvm::relay::ReshapeRel(tvm::runtime::Array<tvm::Type, void> const&, int, tvm::Attrs const&, tvm::TypeReporter const&)\n  File \"/workspace/tvm/src/relay/op/tensor/transform.cc\", line 795\nInternalError: Check failed: oshape_sum == data_shape_sum (512 vs. 3584) : Input tensor shape(1,512,7,1) and reshaped shape(1,512) are not compatible!"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import tvm\n",
    "from tvm import relay\n",
    "from tvm.contrib import graph_executor\n",
    "\n",
    "# Load the ONNX model\n",
    "onnx_model = onnx.load(\"resnet18_traced.onnx\")\n",
    "\n",
    "# Input shape dictionary. Ensure \"input\" matches the actual input name in your ONNX model.\n",
    "# You can check this using onnx.load(\"resnet18.onnx\").graph.input[0].name\n",
    "input_name  = onnx_model.graph.input[0].name\n",
    "input_shape = (1,3,224,224)\n",
    "input_dtype = \"float32\"\n",
    "\n",
    "# Import the ONNX model to TVM Relay format\n",
    "# The error in your traceback (from_onnx(onnx_model, shape_dict)) implies onnx.mapping was called internally.\n",
    "# Upgrading onnx should fix this if it's a version incompatibility.\n",
    "# mod, params = relay.frontend.from_onnx(onnx_model, shape_dict)\n",
    "\n",
    "shape_dict = {input_name: input_shape}\n",
    "mod, params = relay.frontend.from_onnx(onnx_model, shape_dict)\n",
    "\n",
    "# mod, params = relay.frontend.from_onnx(\n",
    "#     onnx_model,\n",
    "#     shape={input_name: input_shape},\n",
    "#     dtype={input_name: input_dtype},\n",
    "#     freeze_params=True,\n",
    "# )\n",
    "\n",
    "# Set the compilation target. \"llvm\" for CPU, \"cuda\" for NVIDIA GPUs.\n",
    "target = \"llvm\" # or \"cuda\" if you have a GPU and CUDA installed\n",
    "\n",
    "# Compile the model with TVM\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    lib = relay.build(mod, target=target, params=params)\n",
    "\n",
    "# Save the compiled TVM artifacts\n",
    "# These files can then be loaded by the TVM runtime for inference.\n",
    "lib.export_library(\"deploy_lib_cpu.so\")\n",
    "with open(\"deploy_graph.json\", \"w\") as f:\n",
    "    f.write(lib.get_graph_json())\n",
    "with open(\"deploy_params.params\", \"wb\") as f:\n",
    "    f.write(tvm.runtime.save_param_dict(lib.get_params()))\n",
    "\n",
    "print(\"Compiled and exported TVM artifacts:\")\n",
    "print(\" - deploy_lib_cpu.so\")\n",
    "print(\" - deploy_graph.json\")\n",
    "print(\" - deploy_params.params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aebd26c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Traceback (most recent call last):\n  8: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::transform::Pass, tvm::IRModule)>::AssignTypedLambda<tvm::transform::{lambda(tvm::transform::Pass, tvm::IRModule)#7}>(tvm::transform::{lambda(tvm::transform::Pass, tvm::IRModule)#7}, std::string)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)\n  7: tvm::transform::Pass::operator()(tvm::IRModule) const\n  6: tvm::transform::Pass::operator()(tvm::IRModule, tvm::transform::PassContext const&) const\n  5: tvm::transform::ModulePassNode::operator()(tvm::IRModule, tvm::transform::PassContext const&) const\n  4: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::IRModule, tvm::transform::PassContext)>::AssignTypedLambda<tvm::relay::transform::InferType()::{lambda(tvm::IRModule, tvm::transform::PassContext const&)#1}>(tvm::relay::transform::InferType()::{lambda(tvm::IRModule, tvm::transform::PassContext const&)#1})::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)\n  3: tvm::relay::TypeInferencer::Infer(tvm::GlobalVar, tvm::relay::Function)\n  2: tvm::relay::TypeSolver::Solve()\n  1: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<bool (tvm::runtime::Array<tvm::Type, void> const&, int, tvm::Attrs const&, tvm::TypeReporter const&)>::AssignTypedLambda<bool (*)(tvm::runtime::Array<tvm::Type, void> const&, int, tvm::Attrs const&, tvm::TypeReporter const&)>(bool (*)(tvm::runtime::Array<tvm::Type, void> const&, int, tvm::Attrs const&, tvm::TypeReporter const&))::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)\n  0: tvm::relay::ReshapeRel(tvm::runtime::Array<tvm::Type, void> const&, int, tvm::Attrs const&, tvm::TypeReporter const&)\n  File \"/workspace/tvm/src/relay/op/tensor/transform.cc\", line 795\nInternalError: Check failed: oshape_sum == data_shape_sum (512 vs. 3584) : Input tensor shape(1,512,7,1) and reshaped shape(1,512) are not compatible!",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInternalError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     24\u001b[39m dtype_config = {input_name: input_type}\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Convert ONNX model to Relay\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Pass the input configuration as separate arguments\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m mod, params = \u001b[43mrelay\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrontend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_onnx\u001b[49m\u001b[43m(\u001b[49m\u001b[43monnx_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshape_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# --- CHOOSE YOUR TARGET HERE ---\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# Example 1: NVIDIA GPU\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# target = \"cuda\"\u001b[39;00m\n\u001b[32m     33\u001b[39m \n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# Example 2: Generic CPU\u001b[39;00m\n\u001b[32m     35\u001b[39m target = \u001b[33m\"\u001b[39m\u001b[33mllvm\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/tvm/relay/frontend/onnx.py:7220\u001b[39m, in \u001b[36mfrom_onnx\u001b[39m\u001b[34m(model, shape, dtype, opset, freeze_params, convert_config, export_node_renamed_model_path)\u001b[39m\n\u001b[32m   7218\u001b[39m \u001b[38;5;66;03m# Use the graph proto as a scope so that ops can access other nodes if needed.\u001b[39;00m\n\u001b[32m   7219\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m g:\n\u001b[32m-> \u001b[39m\u001b[32m7220\u001b[39m     mod, params = \u001b[43mg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_onnx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   7222\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m export_node_renamed_model_path:\n\u001b[32m   7223\u001b[39m     export_model(export_node_renamed_model_path, graph)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/tvm/relay/frontend/onnx.py:6839\u001b[39m, in \u001b[36mGraphProto.from_onnx\u001b[39m\u001b[34m(self, graph, opset, get_output_expr)\u001b[39m\n\u001b[32m   6837\u001b[39m \u001b[38;5;28mself\u001b[39m._check_user_inputs_in_outermost_graph_scope()\n\u001b[32m   6838\u001b[39m \u001b[38;5;28mself\u001b[39m._check_for_unsupported_ops(graph)\n\u001b[32m-> \u001b[39m\u001b[32m6839\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_construct_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6841\u001b[39m \u001b[38;5;66;03m# now return the outputs\u001b[39;00m\n\u001b[32m   6842\u001b[39m outputs = [\u001b[38;5;28mself\u001b[39m._nodes[\u001b[38;5;28mself\u001b[39m._parse_value_proto(i)] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m graph.output]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/tvm/relay/frontend/onnx.py:6954\u001b[39m, in \u001b[36mGraphProto._construct_nodes\u001b[39m\u001b[34m(self, graph)\u001b[39m\n\u001b[32m   6951\u001b[39m attr[\u001b[33m\"\u001b[39m\u001b[33mtvm_custom\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m] = i_name\n\u001b[32m   6952\u001b[39m attr[\u001b[33m\"\u001b[39m\u001b[33mtvm_custom\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mnum_outputs\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mlen\u001b[39m(node_output)\n\u001b[32m-> \u001b[39m\u001b[32m6954\u001b[39m op = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_operator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mopset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6955\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(op, _expr.TupleWrapper):\n\u001b[32m   6956\u001b[39m     outputs_num = \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/tvm/relay/frontend/onnx.py:7078\u001b[39m, in \u001b[36mGraphProto._convert_operator\u001b[39m\u001b[34m(self, op_name, inputs, attrs, opset)\u001b[39m\n\u001b[32m   7076\u001b[39m     sym = get_relay_op(op_name)(*inputs, **attrs)\n\u001b[32m   7077\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m op_name \u001b[38;5;129;01min\u001b[39;00m convert_map:\n\u001b[32m-> \u001b[39m\u001b[32m7078\u001b[39m     sym = \u001b[43mconvert_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   7079\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   7080\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOperator \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mop_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not implemented.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/tvm/relay/frontend/onnx.py:1840\u001b[39m, in \u001b[36mGemm._impl_v1\u001b[39m\u001b[34m(cls, inputs, attr, params)\u001b[39m\n\u001b[32m   1835\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m   1836\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_impl_v1\u001b[39m(\u001b[38;5;28mcls\u001b[39m, inputs, attr, params):\n\u001b[32m   1837\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[32m   1838\u001b[39m         \u001b[38;5;28mlen\u001b[39m(inputs) == \u001b[32m3\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(inputs) == \u001b[32m2\u001b[39m\n\u001b[32m   1839\u001b[39m     ), \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGemm op take 2 or 3 inputs, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(inputs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m given\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1840\u001b[39m     input0_state = \u001b[43minfer_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1841\u001b[39m     dtype = input0_state.checked_type.dtype\n\u001b[32m   1842\u001b[39m     \u001b[38;5;66;03m# Y = alpha * A * B + beta * C\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/tvm/relay/frontend/common.py:505\u001b[39m, in \u001b[36minfer_type\u001b[39m\u001b[34m(node, mod)\u001b[39m\n\u001b[32m    502\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mod \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    503\u001b[39m     new_mod.update(mod)\n\u001b[32m--> \u001b[39m\u001b[32m505\u001b[39m new_mod = \u001b[43m_transform\u001b[49m\u001b[43m.\u001b[49m\u001b[43mInferType\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_mod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    506\u001b[39m entry = new_mod[\u001b[33m\"\u001b[39m\u001b[33mmain\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    507\u001b[39m ret = entry \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, _function.Function) \u001b[38;5;28;01melse\u001b[39;00m entry.body\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/tvm/ir/transform.py:160\u001b[39m, in \u001b[36mPass.__call__\u001b[39m\u001b[34m(self, mod)\u001b[39m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, mod):\n\u001b[32m    147\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Execute the pass. Note that for sequential pass, the dependency among\u001b[39;00m\n\u001b[32m    148\u001b[39m \u001b[33;03m    different passes will be resolved in the backend.\u001b[39;00m\n\u001b[32m    149\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    158\u001b[39m \u001b[33;03m        The updated module after applying this pass.\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ffi_transform_api\u001b[49m\u001b[43m.\u001b[49m\u001b[43mRunPass\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmod\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/tvm/_ffi/_ctypes/packed_func.py:239\u001b[39m, in \u001b[36mPackedFuncBase.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    227\u001b[39m ret_tcode = ctypes.c_int()\n\u001b[32m    228\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    229\u001b[39m     _LIB.TVMFuncCall(\n\u001b[32m    230\u001b[39m         \u001b[38;5;28mself\u001b[39m.handle,\n\u001b[32m   (...)\u001b[39m\u001b[32m    237\u001b[39m     != \u001b[32m0\u001b[39m\n\u001b[32m    238\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m     \u001b[43mraise_last_ffi_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    240\u001b[39m _ = temp_args\n\u001b[32m    241\u001b[39m _ = args\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/tvm/_ffi/base.py:481\u001b[39m, in \u001b[36mraise_last_ffi_error\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    475\u001b[39m \u001b[38;5;66;03m# The exception PyObject may contain a large amount of state,\u001b[39;00m\n\u001b[32m    476\u001b[39m \u001b[38;5;66;03m# including all stack frames that may be inspected in a later\u001b[39;00m\n\u001b[32m    477\u001b[39m \u001b[38;5;66;03m# PDB post-mortem.  Therefore, we must make sure to remove the\u001b[39;00m\n\u001b[32m    478\u001b[39m \u001b[38;5;66;03m# underlying PyObject* from the C++ side after we retrieve it.\u001b[39;00m\n\u001b[32m    479\u001b[39m _LIB.TVMDropLastPythonError()\n\u001b[32m--> \u001b[39m\u001b[32m481\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m py_err\n",
      "\u001b[31mInternalError\u001b[39m: Traceback (most recent call last):\n  8: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::transform::Pass, tvm::IRModule)>::AssignTypedLambda<tvm::transform::{lambda(tvm::transform::Pass, tvm::IRModule)#7}>(tvm::transform::{lambda(tvm::transform::Pass, tvm::IRModule)#7}, std::string)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)\n  7: tvm::transform::Pass::operator()(tvm::IRModule) const\n  6: tvm::transform::Pass::operator()(tvm::IRModule, tvm::transform::PassContext const&) const\n  5: tvm::transform::ModulePassNode::operator()(tvm::IRModule, tvm::transform::PassContext const&) const\n  4: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::IRModule, tvm::transform::PassContext)>::AssignTypedLambda<tvm::relay::transform::InferType()::{lambda(tvm::IRModule, tvm::transform::PassContext const&)#1}>(tvm::relay::transform::InferType()::{lambda(tvm::IRModule, tvm::transform::PassContext const&)#1})::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)\n  3: tvm::relay::TypeInferencer::Infer(tvm::GlobalVar, tvm::relay::Function)\n  2: tvm::relay::TypeSolver::Solve()\n  1: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<bool (tvm::runtime::Array<tvm::Type, void> const&, int, tvm::Attrs const&, tvm::TypeReporter const&)>::AssignTypedLambda<bool (*)(tvm::runtime::Array<tvm::Type, void> const&, int, tvm::Attrs const&, tvm::TypeReporter const&)>(bool (*)(tvm::runtime::Array<tvm::Type, void> const&, int, tvm::Attrs const&, tvm::TypeReporter const&))::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)\n  0: tvm::relay::ReshapeRel(tvm::runtime::Array<tvm::Type, void> const&, int, tvm::Attrs const&, tvm::TypeReporter const&)\n  File \"/workspace/tvm/src/relay/op/tensor/transform.cc\", line 795\nInternalError: Check failed: oshape_sum == data_shape_sum (512 vs. 3584) : Input tensor shape(1,512,7,1) and reshaped shape(1,512) are not compatible!"
     ]
    }
   ],
   "source": [
    "import tvm\n",
    "from tvm import relay\n",
    "from tvm.contrib import graph_executor\n",
    "import onnx\n",
    "import numpy as np # Import numpy for creating example input data\n",
    "\n",
    "# Load the ONNX model\n",
    "onnx_model = onnx.load(\"resnet18.onnx\")\n",
    "\n",
    "# --- IMPORTANT: Determine your model's input name and shape ---\n",
    "# You'll need to inspect your ONNX model to get this.\n",
    "# For ResNet18, a common input shape is (batch_size, channels, height, width)\n",
    "# e.g., (1, 3, 224, 224) for a single image, 3 color channels, 224x224 pixels.\n",
    "# The input name is often \"input.1\" or \"input\" or something similar.\n",
    "# You can check this by printing onnx_model.graph.input\n",
    "# For demonstration, let's assume \"input.1\" as the input name and shape (1, 3, 224, 224)\n",
    "\n",
    "input_name = onnx_model.graph.input[0].name # Get the input name from the ONNX model\n",
    "input_shape = (1, 3, 224, 224) # Define the desired input shape\n",
    "input_type = \"float32\" # Define the input data type\n",
    "\n",
    "# Create a dictionary for the input configuration\n",
    "shape_config = {input_name: input_shape}\n",
    "dtype_config = {input_name: input_type}\n",
    "\n",
    "# Convert ONNX model to Relay\n",
    "# Pass the input configuration as separate arguments\n",
    "mod, params = relay.frontend.from_onnx(onnx_model, shape=shape_config, dtype=dtype_config)\n",
    "\n",
    "# --- CHOOSE YOUR TARGET HERE ---\n",
    "# Example 1: NVIDIA GPU\n",
    "# target = \"cuda\"\n",
    "\n",
    "# Example 2: Generic CPU\n",
    "target = \"llvm\"\n",
    "\n",
    "# -------------------------------\n",
    "\n",
    "# Compile the model\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    lib = relay.build(mod, target=target, params=params)\n",
    "\n",
    "print(f\"Model compiled successfully for target: {target}\")\n",
    "\n",
    "# --- Optional: Run inference for verification ---\n",
    "# If you want to run it, you'll need to create some dummy input data\n",
    "dev = tvm.device(str(target), 0) # Use str(target) to ensure it's a string\n",
    "\n",
    "# Create dummy input data\n",
    "dummy_input = np.random.rand(*input_shape).astype(input_type)\n",
    "\n",
    "# Load the compiled module\n",
    "module = graph_executor.GraphModule(lib[\"default\"](dev))\n",
    "\n",
    "# Set input\n",
    "module.set_input(input_name, tvm.nd.array(dummy_input))\n",
    "\n",
    "# Execute\n",
    "module.run()\n",
    "\n",
    "# Get output (assuming one output)\n",
    "output = module.get_output(0).asnumpy()\n",
    "print(f\"Inference successful. Output shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c1bcc750",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3436/4219831679.py:9: UserWarning: # 'dynamic_axes' is not recommended when dynamo=True, and may lead to 'torch._dynamo.exc.UserError: Constraints violated.' Supply the 'dynamic_shapes' argument instead if export is unsuccessful.\n",
      "  torch.onnx.export(\n",
      "W1024 00:54:14.648000 3436 torch/onnx/_internal/exporter/_compat.py:114] Setting ONNX exporter to use operator set version 18 because the requested opset_version 13 is a lower version than we have implementations for. Automatic version conversion will be performed, which may not be successful at converting to the requested version. If version conversion is unsuccessful, the opset version of the exported model will be kept at 18. Please consider setting opset_version >=18 to leverage latest ONNX features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Obtain model graph for `MobileNetV2([...]` with `torch.export.export(..., strict=False)`...\n",
      "[torch.onnx] Obtain model graph for `MobileNetV2([...]` with `torch.export.export(..., strict=False)`... ✅\n",
      "[torch.onnx] Run decomposition...\n",
      "[torch.onnx] Run decomposition... ✅\n",
      "[torch.onnx] Translate the graph into ONNX...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model version conversion is not supported by the onnxscript version converter and fallback is enabled. The model will be converted using the onnx C API (target version: 13).\n",
      "Failed to convert the model to the target version 13 using the ONNX C API. The model was not modified\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vscode/.local/lib/python3.11/site-packages/onnxscript/version_converter/__init__.py\", line 127, in call\n",
      "    converted_proto = _c_api_utils.call_onnx_api(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vscode/.local/lib/python3.11/site-packages/onnxscript/version_converter/_c_api_utils.py\", line 65, in call_onnx_api\n",
      "    result = func(proto)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/vscode/.local/lib/python3.11/site-packages/onnxscript/version_converter/__init__.py\", line 122, in _partial_convert_version\n",
      "    return onnx.version_converter.convert_version(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vscode/.local/lib/python3.11/site-packages/onnx/version_converter.py\", line 39, in convert_version\n",
      "    - Gemm from Opset 6 to Opset 7\n",
      "                      ^^^^^^^^^^^^^\n",
      "RuntimeError: /github/workspace/onnx/version_converter/adapters/axes_input_to_attribute.h:65: adapt: Assertion `node->hasAttribute(kaxes)` failed: No initializer or constant input to node found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Translate the graph into ONNX... ✅\n",
      "Saved mobilenetv2.onnx\n"
     ]
    }
   ],
   "source": [
    "# 1) Export to ONNX\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "model = models.mobilenet_v2(weights=None)  # or weights='IMAGENET1K_V1' if you want pretrained\n",
    "model.eval()\n",
    "\n",
    "dummy = torch.randn(1, 3, 224, 224)\n",
    "torch.onnx.export(\n",
    "    model, dummy, \"mobilenetv2.onnx\",\n",
    "    input_names=[\"input\"], output_names=[\"logits\"],\n",
    "    opset_version=13,\n",
    "    do_constant_folding=True,\n",
    "    dynamic_axes={\"input\": {0: \"batch\"}, \"logits\": {0: \"batch\"}}\n",
    ")\n",
    "print(\"Saved mobilenetv2.onnx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9bac424c",
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Traceback (most recent call last):\n  8: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::transform::Pass, tvm::IRModule)>::AssignTypedLambda<tvm::transform::{lambda(tvm::transform::Pass, tvm::IRModule)#7}>(tvm::transform::{lambda(tvm::transform::Pass, tvm::IRModule)#7}, std::string)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)\n  7: tvm::transform::Pass::operator()(tvm::IRModule) const\n  6: tvm::transform::Pass::operator()(tvm::IRModule, tvm::transform::PassContext const&) const\n  5: tvm::transform::ModulePassNode::operator()(tvm::IRModule, tvm::transform::PassContext const&) const\n  4: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::IRModule, tvm::transform::PassContext)>::AssignTypedLambda<tvm::relay::transform::InferType()::{lambda(tvm::IRModule, tvm::transform::PassContext const&)#1}>(tvm::relay::transform::InferType()::{lambda(tvm::IRModule, tvm::transform::PassContext const&)#1})::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)\n  3: tvm::relay::TypeInferencer::Infer(tvm::GlobalVar, tvm::relay::Function)\n  2: tvm::relay::TypeSolver::Solve()\n  1: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<bool (tvm::runtime::Array<tvm::Type, void> const&, int, tvm::Attrs const&, tvm::TypeReporter const&)>::AssignTypedLambda<bool (*)(tvm::runtime::Array<tvm::Type, void> const&, int, tvm::Attrs const&, tvm::TypeReporter const&)>(bool (*)(tvm::runtime::Array<tvm::Type, void> const&, int, tvm::Attrs const&, tvm::TypeReporter const&))::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)\n  0: tvm::relay::ReshapeRel(tvm::runtime::Array<tvm::Type, void> const&, int, tvm::Attrs const&, tvm::TypeReporter const&)\n  File \"/workspace/tvm/src/relay/op/tensor/transform.cc\", line 795\nInternalError: Check failed: oshape_sum == data_shape_sum (1280 vs. 8960) : Input tensor shape(1,1280,7,1) and reshaped shape(1,1280) are not compatible!",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInternalError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m onnx_model = onnx.load(\u001b[33m\"\u001b[39m\u001b[33mmobilenetv2.onnx\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m shape_dict = {\u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m: (\u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m224\u001b[39m, \u001b[32m224\u001b[39m)}\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m mod, params = \u001b[43mrelay\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrontend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_onnx\u001b[49m\u001b[43m(\u001b[49m\u001b[43monnx_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m target = \u001b[33m\"\u001b[39m\u001b[33mllvm\u001b[39m\u001b[33m\"\u001b[39m              \u001b[38;5;66;03m# CPU\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# target = tvm.target.cuda() # or \"cuda\" if you have GPU\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/tvm/relay/frontend/onnx.py:7220\u001b[39m, in \u001b[36mfrom_onnx\u001b[39m\u001b[34m(model, shape, dtype, opset, freeze_params, convert_config, export_node_renamed_model_path)\u001b[39m\n\u001b[32m   7218\u001b[39m \u001b[38;5;66;03m# Use the graph proto as a scope so that ops can access other nodes if needed.\u001b[39;00m\n\u001b[32m   7219\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m g:\n\u001b[32m-> \u001b[39m\u001b[32m7220\u001b[39m     mod, params = \u001b[43mg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_onnx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   7222\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m export_node_renamed_model_path:\n\u001b[32m   7223\u001b[39m     export_model(export_node_renamed_model_path, graph)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/tvm/relay/frontend/onnx.py:6839\u001b[39m, in \u001b[36mGraphProto.from_onnx\u001b[39m\u001b[34m(self, graph, opset, get_output_expr)\u001b[39m\n\u001b[32m   6837\u001b[39m \u001b[38;5;28mself\u001b[39m._check_user_inputs_in_outermost_graph_scope()\n\u001b[32m   6838\u001b[39m \u001b[38;5;28mself\u001b[39m._check_for_unsupported_ops(graph)\n\u001b[32m-> \u001b[39m\u001b[32m6839\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_construct_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6841\u001b[39m \u001b[38;5;66;03m# now return the outputs\u001b[39;00m\n\u001b[32m   6842\u001b[39m outputs = [\u001b[38;5;28mself\u001b[39m._nodes[\u001b[38;5;28mself\u001b[39m._parse_value_proto(i)] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m graph.output]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/tvm/relay/frontend/onnx.py:6954\u001b[39m, in \u001b[36mGraphProto._construct_nodes\u001b[39m\u001b[34m(self, graph)\u001b[39m\n\u001b[32m   6951\u001b[39m attr[\u001b[33m\"\u001b[39m\u001b[33mtvm_custom\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m] = i_name\n\u001b[32m   6952\u001b[39m attr[\u001b[33m\"\u001b[39m\u001b[33mtvm_custom\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mnum_outputs\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mlen\u001b[39m(node_output)\n\u001b[32m-> \u001b[39m\u001b[32m6954\u001b[39m op = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_operator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mopset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6955\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(op, _expr.TupleWrapper):\n\u001b[32m   6956\u001b[39m     outputs_num = \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/tvm/relay/frontend/onnx.py:7078\u001b[39m, in \u001b[36mGraphProto._convert_operator\u001b[39m\u001b[34m(self, op_name, inputs, attrs, opset)\u001b[39m\n\u001b[32m   7076\u001b[39m     sym = get_relay_op(op_name)(*inputs, **attrs)\n\u001b[32m   7077\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m op_name \u001b[38;5;129;01min\u001b[39;00m convert_map:\n\u001b[32m-> \u001b[39m\u001b[32m7078\u001b[39m     sym = \u001b[43mconvert_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   7079\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   7080\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOperator \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mop_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not implemented.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/tvm/relay/frontend/onnx.py:1840\u001b[39m, in \u001b[36mGemm._impl_v1\u001b[39m\u001b[34m(cls, inputs, attr, params)\u001b[39m\n\u001b[32m   1835\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m   1836\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_impl_v1\u001b[39m(\u001b[38;5;28mcls\u001b[39m, inputs, attr, params):\n\u001b[32m   1837\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[32m   1838\u001b[39m         \u001b[38;5;28mlen\u001b[39m(inputs) == \u001b[32m3\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(inputs) == \u001b[32m2\u001b[39m\n\u001b[32m   1839\u001b[39m     ), \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGemm op take 2 or 3 inputs, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(inputs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m given\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1840\u001b[39m     input0_state = \u001b[43minfer_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1841\u001b[39m     dtype = input0_state.checked_type.dtype\n\u001b[32m   1842\u001b[39m     \u001b[38;5;66;03m# Y = alpha * A * B + beta * C\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/tvm/relay/frontend/common.py:505\u001b[39m, in \u001b[36minfer_type\u001b[39m\u001b[34m(node, mod)\u001b[39m\n\u001b[32m    502\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mod \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    503\u001b[39m     new_mod.update(mod)\n\u001b[32m--> \u001b[39m\u001b[32m505\u001b[39m new_mod = \u001b[43m_transform\u001b[49m\u001b[43m.\u001b[49m\u001b[43mInferType\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_mod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    506\u001b[39m entry = new_mod[\u001b[33m\"\u001b[39m\u001b[33mmain\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    507\u001b[39m ret = entry \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, _function.Function) \u001b[38;5;28;01melse\u001b[39;00m entry.body\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/tvm/ir/transform.py:160\u001b[39m, in \u001b[36mPass.__call__\u001b[39m\u001b[34m(self, mod)\u001b[39m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, mod):\n\u001b[32m    147\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Execute the pass. Note that for sequential pass, the dependency among\u001b[39;00m\n\u001b[32m    148\u001b[39m \u001b[33;03m    different passes will be resolved in the backend.\u001b[39;00m\n\u001b[32m    149\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    158\u001b[39m \u001b[33;03m        The updated module after applying this pass.\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ffi_transform_api\u001b[49m\u001b[43m.\u001b[49m\u001b[43mRunPass\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmod\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/tvm/_ffi/_ctypes/packed_func.py:239\u001b[39m, in \u001b[36mPackedFuncBase.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    227\u001b[39m ret_tcode = ctypes.c_int()\n\u001b[32m    228\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    229\u001b[39m     _LIB.TVMFuncCall(\n\u001b[32m    230\u001b[39m         \u001b[38;5;28mself\u001b[39m.handle,\n\u001b[32m   (...)\u001b[39m\u001b[32m    237\u001b[39m     != \u001b[32m0\u001b[39m\n\u001b[32m    238\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m     \u001b[43mraise_last_ffi_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    240\u001b[39m _ = temp_args\n\u001b[32m    241\u001b[39m _ = args\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/tvm/_ffi/base.py:481\u001b[39m, in \u001b[36mraise_last_ffi_error\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    475\u001b[39m \u001b[38;5;66;03m# The exception PyObject may contain a large amount of state,\u001b[39;00m\n\u001b[32m    476\u001b[39m \u001b[38;5;66;03m# including all stack frames that may be inspected in a later\u001b[39;00m\n\u001b[32m    477\u001b[39m \u001b[38;5;66;03m# PDB post-mortem.  Therefore, we must make sure to remove the\u001b[39;00m\n\u001b[32m    478\u001b[39m \u001b[38;5;66;03m# underlying PyObject* from the C++ side after we retrieve it.\u001b[39;00m\n\u001b[32m    479\u001b[39m _LIB.TVMDropLastPythonError()\n\u001b[32m--> \u001b[39m\u001b[32m481\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m py_err\n",
      "\u001b[31mInternalError\u001b[39m: Traceback (most recent call last):\n  8: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::transform::Pass, tvm::IRModule)>::AssignTypedLambda<tvm::transform::{lambda(tvm::transform::Pass, tvm::IRModule)#7}>(tvm::transform::{lambda(tvm::transform::Pass, tvm::IRModule)#7}, std::string)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)\n  7: tvm::transform::Pass::operator()(tvm::IRModule) const\n  6: tvm::transform::Pass::operator()(tvm::IRModule, tvm::transform::PassContext const&) const\n  5: tvm::transform::ModulePassNode::operator()(tvm::IRModule, tvm::transform::PassContext const&) const\n  4: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::IRModule, tvm::transform::PassContext)>::AssignTypedLambda<tvm::relay::transform::InferType()::{lambda(tvm::IRModule, tvm::transform::PassContext const&)#1}>(tvm::relay::transform::InferType()::{lambda(tvm::IRModule, tvm::transform::PassContext const&)#1})::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)\n  3: tvm::relay::TypeInferencer::Infer(tvm::GlobalVar, tvm::relay::Function)\n  2: tvm::relay::TypeSolver::Solve()\n  1: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<bool (tvm::runtime::Array<tvm::Type, void> const&, int, tvm::Attrs const&, tvm::TypeReporter const&)>::AssignTypedLambda<bool (*)(tvm::runtime::Array<tvm::Type, void> const&, int, tvm::Attrs const&, tvm::TypeReporter const&)>(bool (*)(tvm::runtime::Array<tvm::Type, void> const&, int, tvm::Attrs const&, tvm::TypeReporter const&))::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)\n  0: tvm::relay::ReshapeRel(tvm::runtime::Array<tvm::Type, void> const&, int, tvm::Attrs const&, tvm::TypeReporter const&)\n  File \"/workspace/tvm/src/relay/op/tensor/transform.cc\", line 795\nInternalError: Check failed: oshape_sum == data_shape_sum (1280 vs. 8960) : Input tensor shape(1,1280,7,1) and reshaped shape(1,1280) are not compatible!"
     ]
    }
   ],
   "source": [
    "# 2) Compile with TVM\n",
    "import onnx, tvm\n",
    "from tvm import relay\n",
    "from tvm.contrib import graph_executor\n",
    "import numpy as np\n",
    "\n",
    "onnx_model = onnx.load(\"mobilenetv2.onnx\")\n",
    "\n",
    "shape_dict = {\"input\": (1, 3, 224, 224)}\n",
    "mod, params = relay.frontend.from_onnx(onnx_model, shape_dict)\n",
    "\n",
    "target = \"llvm\"              # CPU\n",
    "# target = tvm.target.cuda() # or \"cuda\" if you have GPU\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    lib = relay.build(mod, target=target, params=params)\n",
    "\n",
    "dev = tvm.cpu(0)             # or tvm.cuda(0)\n",
    "module = graph_executor.GraphModule(lib[\"default\"](dev))\n",
    "\n",
    "# run a quick check\n",
    "inp = np.random.randn(1, 3, 224, 224).astype(\"float32\")\n",
    "module.set_input(\"input\", tvm.nd.array(inp))\n",
    "module.run()\n",
    "out = module.get_output(0).numpy()\n",
    "print(out.shape)  # (1, 1000)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
